#! /usr/bin/perl

use strict;
use Data::Dumper;
use Getopt::Long;
#use Date::Time libdatetime-perl

my $version = '0.20180315';

my $help = undef;
my $json = undef;
my $log_type = undef;
my $date_format = '%b %d %T';
# number of whitespace-separated bits of the date:
my $date_elements = 3;
my $fields_string = "to,from,subject";
my $show_header_row = undef;
my $return_log_lines = undef;
my $show_version = undef;

my @fields = ();
my @patterns = ();
my $and = undef;

GetOptions (
	"and|a" => \$and,
	"help|h" => \$help,
	"log-type|t" => \$log_type,
	"json" => \$json,
	"header" => \$show_header_row,
	"date-format" => \$date_format,
	"num-date-elements" => \$date_elements,
	"patterns|p=s" => \@patterns,
	"fields|f=s" => \$fields_string,
	"log-lines" => \$return_log_lines,
	"version" => \$show_version,
) or die("Error in command line arguments\n");

print "umg (universal maillog grepper) version $version\n" and exit if $show_version;
usage_and_exit() if $help;

@fields = split(m/,\s*/, $fields_string);

my $maillog = shift;

# First, parse the passed maillog to get the messages out of it into $log_data,
# which is an array of hashes.

my $maillog_fh;
if( $maillog && -f $maillog ){
	open ($maillog_fh, "<", $maillog) or die("Failed to open maillog '$maillog' for reading : $!");
}elsif(! -t STDIN ){
	$maillog_fh = \*STDIN;
}else{
	print STDERR "No maillog provided, and nothing on stdin\n";
	usage_and_exit();
}
$log_type = get_log_type($maillog_fh) unless $log_type;

my $log_data;
if($log_type eq 'postfix'){
	$log_data = postfix_parse_log($maillog_fh);
}elsif($log_type eq 'qmail'){
	$log_data = qmail_parse_log($maillog_fh);
}else{
	print "ERROR: Failed to guess log type";
}


# Then go through our --pattern arguments and split them into field/regex pairs
# and make a hash for later use
my %regexes;
debug("Assembling regexes");
foreach my $search (@patterns){
	my ($field,$pattern) = split(m/:/, $search);
	push(@{$regexes{$field}}, qr/$pattern/);
	debug("  $field: $pattern\n");
}
my $num_regexes = keys(%regexes);

# The important bit, grepping.
# Pointedly, if we've no regexes ($num_regexes == 0) then effectively every message 
# matches. 

my(%field_lengths,@results);
foreach my $message (@{$log_data}){
	if(grep_message($message, \%regexes, $and) || $num_regexes == 0){
		if($return_log_lines){
			push(@results, $message->{log_lines});
		}else{
			$message = trim_message($message, \@fields);
			foreach my $field (@fields){
				$field_lengths{$field} = length($message->{$field}) if length($message->{$field}) > $field_lengths{$field};
			}
			push(@results,$message);
		}
	}
}

if($json){
	require JSON;
	my $json = JSON->new->allow_nonref;
	print $json->pretty->encode(\@results);
	exit;
}

if($return_log_lines){
	print_log_lines(\@results);
}else{
	print_results(\@fields, \%field_lengths, \@results);
}

# # #
# #
#

sub print_log_lines{
	my $results = shift;
	foreach my $message (@{$results}){
		foreach my $line (@{$message}){
			print $line."\n";
		}
		print "\n\n";
	}
}

sub print_results{

	my $fields = shift;
	my $field_lengths = shift;
	my $results = shift;

	foreach my $field_name (keys(%{$field_lengths})){
		$field_lengths->{$field_name} = $field_lengths->{$field_name} + 3;
	}

	if($show_header_row){
		foreach my $field (@{$fields}){
			printf("%-$field_lengths->{$field}s", $field);
		}
		print "\n";
	}


	foreach my $message (@{$results}){
		foreach my $field (@{$fields}){
			printf("%-$field_lengths->{$field}s", $message->{$field});
		}
		print "\n";
	}

}


sub trim_message{
	my $message = shift;
	my $new_message;
	my $fields = shift;
	return $message if($fields[0] eq '_ALL_');
	foreach my $field (@{$fields}){
		$new_message->{$field} = $message->{$field};
	}
	return $new_message;
}

sub grep_message{
	my $message = shift;
	my $regexes = shift;
	my $and = shift;
	my $num_matches = 0;
	foreach my $message_field (keys(%{$message})){
		next unless $regexes{$message_field};
		foreach my $pattern(@{$regexes{$message_field}}){
			if($message->{$message_field} =~ m/$pattern/i){
				debug("[$message->{message_id}] $message_field: $message->{$message_field} matches $pattern\n");
				$num_matches++;
				return 1 unless $and;
				last;
			}
		}
	}
	if($and and $num_matches == $num_regexes){
		debug("[$message->{message_id}]    num_matches: $num_matches; num_regexes: $num_regexes\n");
		return 1;
	}
	return undef;
}

sub postfix_parse_log{
	my $fh = shift;
	my @log_data;
	my %messages;

	$date_elements--;


	require Time::Piece;
	Time::Piece->import;

	my %per_pid_log_lines;

	while(my $line = readline($fh)){
		chomp($line);
		next unless $line =~ m/postfix/;
		if($line =~ m#postfix/smtpd\[(\d+)\]: ([[A-Z0-9]+): client=(\S+)\[(\d+\.\d+\.\d+\.\d+)\]#){
			my $pid = $1;
			my $id = $2;

			# Postfix queue IDs are guaranteed to never overlap, but not
			# to be unique over any length of time of more than a second.
			# Deal here with seeing the same ID twice.
			if($messages{$id}){
				my $old_message = $messages{$id};
				my $old_message_new_id = $id.$old_message->{timestamp_start};
				$messages{$old_message_new_id} = $old_message;
				delete($messages{$id});
			}

			$messages{$id}->{timestamp_start} = get_epoch_from_line($line, $date_elements, $date_format);
			$messages{$id}->{queue_id} = $id;
			$messages{$id}->{id} = $id;
			$messages{$id}->{remote_hostname} = $3;
			$messages{$id}->{remote_host} = $4;
			if($line =~ m#sasl_username=(\S+)#){
				$messages{$id}->{auth_username} = $1;
			}
			if($per_pid_log_lines{smtpd}->{$pid}){
				foreach my $key (keys(%{$per_pid_log_lines{smtpd}->{$pid}})){
					$messages{$id}->{log_lines}->{$key} = $per_pid_log_lines{smtpd}->{$pid}->{$key};
				}
				delete($per_pid_log_lines{smtpd}->{$pid});
			}
			$messages{$id}->{log_lines}->{$.} = $line;
		}elsif($line =~ m#postfix/cleanup\[\d+\]: ([A-Z0-9]+): warning: header (\S+): (.+) from (\S+); from=+#){
			my $id = $1;
			my $header_name = $2;
			my $header_content = $3;
			if($header_name =~ m/^subject$/i){
				$messages{$id}->{subject} = $header_content
			}else{
				$messages{$id}->{headers}->{$header_name} = $header_content;
			}
			$messages{$id}->{log_lines}->{$.} = $line;
		}elsif($line =~ m#postfix/qmgr\[\d+\]: ([A-Z0-9]+): removed#){
			my $id = $1;
			$messages{$id}->{log_lines}->{$.} = $line;
			

			my %message = %{$messages{$id}};

			my %log_lines = %{$message{log_lines}};
			delete($message{log_lines});
			my @log_lines;
			foreach my $key (sort(keys(%log_lines))){
				push(@log_lines, $log_lines{$key});
			}
			$message{log_lines} = \@log_lines;
			push(@log_data, \%message);
			delete($messages{$id});
		}elsif($line =~ m#postfix/([a-z]+)\[(\d+)\]:\s+(.+)$#){
			my $daemon = $1;
			my $pid = $2;
			my $rest = $3;
			if($rest =~ m/^(disconnect from|lost connection)/){
				delete($per_pid_log_lines{$daemon}->{$pid})
			}else{
				$per_pid_log_lines{$daemon}->{$pid}->{$.} = $line;
			}
		}elsif($line =~ m#postfix/[a-z]+\[\d+\]: ([A-Z0-9]+): (.+)#){
			my $id = $1;
			my $message =$2;
			foreach my $bit (split m/,\s+/, $message){
				if($bit =~ m#^to=<([^>]+)>#){
					$messages{$id}->{to} = $1;
				}elsif ($bit =~ m#^relay=([\w\d\.]+)\[(\d+\.\d+\.\d+\.\d+)\]#){
					$messages{$id}->{relay_hostname} = $1;
					$messages{$id}->{relay_host} = $2;
					$messages{$id}->{remote_or_local} = "remote";
				}elsif ($bit =~ m#^relay=([a-z]+)$#){
					my $relay = $1;
					$messages{$id}->{relay} = $relay;
					if($relay =~ m/^(local|vacation|virtual)$/){
						$messages{$id}->{remote_or_local} = "local";
					}
				}elsif ($bit =~ m#^status=(\S+)\s+\((.+)\)$#){
					$messages{$id}->{smtp_status} = $1;
					$messages{$id}->{smtp_status_message} = $2;
				}elsif ($bit =~ m#^orig_to=<([^>]+)>#){
					$messages{$id}->{orig_to} = $1;
				}elsif ($bit =~ m#^size=(\d+)#){
					$messages{$id}->{size} = $1;
				}elsif ($bit =~ m#^from=<([^>]+)>#){
					$messages{$id}->{from} = $1;
				}

			}
			$messages{$id}->{log_lines}->{$.} = $line;
		}else{
#			print "$line\n";
		}

	}
	return (\@log_data);
}


sub qmail_parse_log{

	my $fh = shift;

	my $log_data;
	my %delivery_to_message;
	my %message_to_delivery;
	my %messages;

	while(my $line = readline($fh)){
		chomp($line);
		if($line =~ m/(\d{10}).\d+ new msg (\d+)$/){
			my $msg_id = $2;
			$messages{$msg_id}->{timestamp_start} = $1;
			$messages{$msg_id}->{message_id} = $2;
			$messages{$msg_id}->{log_lines}->{$.} = $line;
		}elsif($line =~ m/\d{10}\.\d+ info msg (\d+): bytes (\d+) from <([^\>]+)> qp \d+ uid (\d+)$/){
			my $msg_id = $1;
			$messages{$msg_id}->{size} = $2;
			$messages{$msg_id}->{from} = $3;
			$messages{$msg_id}->{uid} = $4;
			$messages{$msg_id}->{log_lines}->{$.} = $line;
		}elsif($line =~ m/(\d{10})\.\d+ starting delivery (\d+): msg (\d+) to (\S+) (\S+)/){
			my $timestamp = $1;
			my $did = $2;
			my $msg_id = $3;
			# delivery_to_message{delivery_id} = $message_id
			$delivery_to_message{$did} = $msg_id;
			# $messages_to_delivery{message_id} = (delivery_id_1, delivery_id_2, etc.)
			push(@{$message_to_delivery{$msg_id}}, $did);
			$messages{$msg_id}->{deliveries}->{$did}->{delivery_id} = $did;
			$messages{$msg_id}->{deliveries}->{$did}->{timestamp_delivery} = $timestamp;
			$messages{$msg_id}->{deliveries}->{$did}->{remote_or_local} = $4;
			$messages{$msg_id}->{deliveries}->{$did}->{to} = $5;
			$messages{$msg_id}->{deliveries}->{$did}->{log_lines}->{$.} = $line;
		}elsif($line =~ m/(\d{10})\.\d+ delivery (\d+): (\S+): (.+)$/){
			my $did = $2;
			my $msg_id = $delivery_to_message{$did};
			$messages{$msg_id}->{deliveries}->{$did}->{smtp_status} = $3;
			$messages{$msg_id}->{deliveries}->{$did}->{smtp_status_message} = $4;
			$messages{$msg_id}->{deliveries}->{$did}->{log_lines}->{$.} = $line;
		}elsif($line =~ m/(\d{10})\.\d+ end msg (\d+)$/){
			my $msg_id = $2;
			$messages{$msg_id}->{timestamp_end} = $1;
			$messages{$msg_id}->{log_lines}->{$.} = $line;

			# Since this is the end of a message:
			my %message = %{$messages{$msg_id}};

			# herein:
			# msg_id is qmail's message id
			# delivery_id is qmail's delivery id
			# message_id is *our* message_id, where a message is a delivery/msg combination
			# message_entry is our complete record of a delivery/msg combination

			my %deliveries = %{$message{deliveries}};
			delete($message{deliveries});
			my %log_lines = %{$message{log_lines}};
			delete($message{log_lines});

			foreach my $delivery_id (sort(keys(%deliveries))){
				my %delivery = %{$messages{$msg_id}->{deliveries}->{$delivery_id}};
				my $message_id = $msg_id."_".$delivery_id."_".$message{timestamp_start};

				my %m_log_lines = %log_lines;
				my %log_lines = (%m_log_lines, %{$delivery{log_lines}});

				$message{message_id} = $message_id;
				my %message_entry = ( %delivery, %message );
				my @log_lines_arr;
				foreach my $key (sort(keys(%log_lines))){
					push(@log_lines_arr, $log_lines{$key});
				}
				$message_entry{log_lines} = \@log_lines_arr;
				push(@{$log_data}, \%message_entry);
			}
			foreach my $delivery_id (keys(%message_to_delivery)){
				delete($delivery_to_message{$delivery_id});
			}
			delete($message_to_delivery{$3});
			delete($messages{$msg_id});
			
		}
	}

	return ($log_data);
}

sub get_epoch_from_line{
	my $line = shift;
	my $date_elements = shift;
	my $date_format = shift;

	my $date_string = join(" ", (split(m/\s+/, $line))[0 ...  $date_elements]);
	$date_string = (localtime())[5] + 1900 ." ".$date_string;
	$date_format = "%Y ".$date_format;
	my $t = Time::Piece->strptime($date_string, $date_format);
	return $t->epoch;
}

sub get_log_type{
	my $fh = shift;
	my $log_type = undef;
	while(my $line = readline($maillog_fh)){
		if($line =~ m/postfix\/\w+/){
			$log_type = 'postfix';
			last;
		}elsif($line =~ m/qmail:/){
			$log_type = 'qmail';
			last;
		}elsif($line =~ m/^\d{10}\.\d{9}/){
			$log_type = 'qmail';
			last;
		}
	}
	seek($fh,0,0);
	return $log_type;
}

sub debug{
	return unless $ENV{DEBUG};
	my $message = shift;
	chomp($message);
	print STDERR "DEBUG: $message\n";
}

sub usage_and_exit{
print <<EOF;

umg - the Univeral Mail Log Grepper

parses various (well, two) forms of mail log into a standard structure, which 
can then be filtered and output either as JSON or something human-readable

USAGE:

   umg [options] <logfile>
   cat /var/log/maillog | umg [options]

   cat qmail_log | tai64nfraction | umg [options]

OPTIONS:

  FILTERING AND OUTPUT
    
    --and, -a
         By default, a message is declared a match if a single argument to --pattern
         matches. Call this to require each message match *every* pattern.

    --fields <field1,field2,field3...>, -f <field1,field2,field3...>
         Which fields to display as a comma-separated string. Default: $fields_string. 
         set this to '_ALL_' to get all of them.

    --json
         Produce a (pretty-printed) JSON structure, rather than a human readable list

    --pattern <field_name>:<string>, -p <field_name>:<string>
          Specifies a pattern to use when filtering, if the field named <field_name>
          contains <string> case-insensitively, it will be declared a match. The 
	  <string> part is interpreted as a Perl regex.
          Specify multiple times to use several patterns.

  
  LOGFILE PARSING AND INPUT

   Either cat the file on stdin or supply it as an argument. For Qmail logfiles using 
   the tai64n timestamp, pipe them through tai64nfraction first.

    --log-type <type>, -t <type>
         override logfile type detection, 'type' may be one of 'qmail' or 
         'postfix' currently

    --date-format <format>; --num-date-elements <num>
         Specify a date format for figuring out the timestamp of log lines 
         containing human-friendly dates. <format> should be a pattern suitable
         for passing to strptime(), and <num> should be the number of leading 
         whitespace-separated elements of the log line to take as the date 
         string. Defaults seem right for both Debian's and RHEL's Postfix/Syslog
	 combinations:
           date-format: $date_format
           num-date-elements: $date_elements


DATA STRUCTURE:

Internally, a hash is created representing each message, some of the keys used
are universal (in that both supported MTAs log them) others are specific to one
or the other. The 'id' field is based on the MTA's own internal ID, but no 
guarantee is made that it will be usefully-so.

Common:
* from                Envelope 'from' address
* id                  A unique ID for the message within the output of umg
* remote_hostname     DNS name of host making inbound connection, if in the log
* remote_host         IP address of host making inbound connection
* remote_or_local     Whether the recipient is local or remote
* size                Size of the message, in bytes
* smtp_status         SMTP mail-sending status
* smtp_status_message Message returned by the remote host on mail-sending
* timestamp_start     Timestamp from the first log-line mentioning the message
* timestamp_end       Timestamp from any 'delivered' or 'finished' log-line
* to                  Recipient address of the email

Qmail-only:
* delivery_id         Qmail's delivery ID (prone to re-use)
* message_id          Qmail's message ID (prone to re-use)
* timestamp_delivery  Timestamp from the 'delivered' log-line
* uid                 UID of the proces submitting the message

Postfix-only
* auth_username       SASL username (Postfix/SASL only)
* queue_id            Postfix's queue ID
* relay               Postfix's relay name
* subject             Where logged, parsed out of cleanup's warnings

additionally, in the JSON, the `log lines` key contains an array of the lines from
the input that were deemed related to the message. These are stripped out of non-
JSON output, and displayed by themselves when --log-lines is used.

EXAMPLES

    get a quick count of mail-delivery status for a particular domain:
  
cat /var/log/syslog | ./umg --fields smtp_status --pattern auth_username:\@domain.com | sort | uniq -c

    See who's been sending all that spam:

cat /var/log/maillog | ./umg --f auth_username -p subject:viagra -p subject:cialis | sort | uniq




EOF
exit;
}
